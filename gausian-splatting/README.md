## Which commits were used

Cloned from [github.com/graphdeco-inria/gaussian-splatting](https://github.com/graphdeco-inria/gaussian-splatting) on March 24, 2025 (commit 54c035f). The submodules were cloned on the same day:

* [simple-knn](https://gitlab.inria.fr/bkerbl/simple-knn.git), main branch (commit 86710c2d)
* [diff-gaussian-rasterization](https://github.com/graphdeco-inria/diff-gaussian-rasterization.git), **3dgs_accel (!)** branch (commit 26ce026)
* [fused-ssim](https://github.com/rahul-goel/fused-ssim.git), main branch (commit 8bdb59f)

# Installation

If you used 3DGS before, you probably have a working conda / pip environment. Feel free to re-use that (and skip the installation instructions below), but note that **our code expects the 3dgs_accel branch of submodules/diff-gaussian-rasterization**. 

### Windows installation

This was tested on Windows 10. We assume that the following has been installed:

* (Mini)Conda
* Visual Studio **2019** with C++ compiler. If you need help installing VS2019, see [this issue](https://github.com/graphdeco-inria/gaussian-splatting/issues/833#issuecomment-2685474546). Add the folder containing `cl.exe` to PATH (of environment variables), for example `C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30133\bin\Hostx64\x64`. I also had to run `"C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Auxiliary\Build\vcvars64.bat"`
* CUDA SDK **11.8** (installed after Visual Studio). I had to do a custom installation and uncheck everything to do with Nsight, except for Nsight NVTX.

Next, create a conda environment and install modules and dependencies. More info for installing pytorch can be found [here](https://pytorch.org/get-started/previous-versions/).

```bash
cd gaussian-splatting   # navigate to the folder holding the 3DGS repository
SET DISTUTILS_USE_SDK=1 # Windows only
conda create --name gaussian-splatting python=3.10
conda activate gaussian-splatting

pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118
pip install plyfile tqdm opencv-python joblib
pip install submodules\diff-gaussian-rasterization
pip install submodules\fused-ssim
pip install submodules\simple-knn
```

### Linux installation

Setting up pytorch etc. in Linux is a bit easier than Windows, so just use the install instructions from [3DGS]([graphdeco-inria/gaussian-splatting: Original reference implementation of "3D Gaussian Splatting for Real-Time Radiance Field Rendering"](https://github.com/graphdeco-inria/gaussian-splatting)) (don't forget branch 3dgs_accel for submodules/diff-gaussian-rasterization).

# Main changes made to original 3DGS repository

* `train_benchmark.py`: 
  
  * Added command line options: 
    
    * `--splat_init`, to switch between 3 splat initialization modes:
      
      * `colmap` : default 3DGS init, from Colmap SfM pointcloud
      * `mvsgaussian` : [MVSGaussian](https://mvsgaussian.github.io/), requires to specify `--ply_path <path/to/points3D.ply>` generated by MVSGaussian.
      * `mvs` : **MVS-Splatting (Ours)**
    
    * `--save_images` to save training renders of certain images at `--test_iterations`.
  
  * Metrics (e.g. psnr, ssim) for test iterations are written to a log file, e.g. `output/*/log_01000it.txt`.

* `readColmapSceneInfo()`: don't save intial point cloud to points3D.ply

* In `GaussianModel`, added `create_from_mvs_bin()` to load in the `points3D_mvs.bin` file from the multi-view-stereo pass (only for `--splat_init mvs`).

# Running

For the **original 3DGS implementation**, which uses COLMAP's sparse points3D.bin to initialize the splats:

```bash
python train_benchmark.py -s <path/to/dataset> 
   --splat_init "colmap"
   --m output/colmap/<dataset>
   --iterations 1000 --optimizer_type sparse_adam 
```

For **MVSGaussian**:

```bash
python train_benchmark.py -s <path/to/dataset> 
   --splat_init "mvsgaussian"
   --m output/mvsgaussian/<dataset>
   --iterations 1000 --optimizer_type sparse_adam 
   --ply_path <path/to/points3D.ply>
```

For **MVS-Splatting (Ours)**, which used mutli-view-stereo to initialize the splats (make sure `dataset/sparse/0/points3D_mvs.bin` exists):

```bash
python train_benchmark.py -s <path/to/dataset> 
   --splat_init "mvs"
   --m output/mvs/<dataset>
   --iterations 1000 --optimizer_type sparse_adam 
   --scaling_lr 0.02 --densify_from_iter 199 --lambda_dssim 0.3
```

Additional options:

```bash
--disable_viewer
--eval   # training/test split (test set = images[2::8], train set is all the other images)
--log <log file name>
```

To benchmark, add `--test_iterations` as desired. In `output/*/log_01000it.txt`, metrics such as the train/test split, L1 loss, duration (in seconds), number of gaussians and memory usage will be saved for each test iteration. By default, the last iteration is set to be a test iteration. For example:

```bash
python train_benchmark.py -s <path/to/dataset> 
   --splat_init "mvs"
   --m output/mvs/<dataset>
   --iterations 1000 --optimizer_type sparse_adam 
   --scaling_lr 0.02 --densify_from_iter 199 --lambda_dssim 0.3
   --test_iterations 1 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 1000
```

> Note 1: the duration in the log file does not include the duration of `training_report()` (since this method has nothing to do with the training, but still takes a long time). So the logged duration will be close to what it would be like if `--test_iterations` was not used.
> 
> Note 2: using `--test_iterations` will slow down the training process, so if you do not want this, do not use it.

If you want to save the renders of certain images at certain iterations, you can do something like:

```bash
python train_benchmark.py -s <path/to/dataset> 
   --splat_init "colmap"
   --m output/mvs/<dataset>
   --iterations 300 --optimizer_type sparse_adam 
   --test_iterations 1 50 100 150 200 250 300
   --save_images "00000000" "00000250"
   --log "render.txt"
```

This will save renders for images `{00000000.jpg, 00000250.jpg}` at iterations `{1, 50, 100, 150, 200, 250, 300}` in the `output/mvs/<dataset>/renders` folder, e.g. `"00000000_00001it.png"` for the first view and iteration 1.

> Note: the `output/mvs/<dataset>/renders` is deleted and remade every time `--save_images` is not empty.

### Reading the log

```bash
python read_log.py <path/to/log_01000it.txt>
```

This python file contains code to interpret the log file produced by running `python train_benchmark.py --iterations 1000`.  Feel free to use your own code though to keep track of PSNR, SSIM, LPIPS, runtime, etc.
